
-- generated by using spec/native_functions_modified.yaml and deps/libtorch/include/ATen/NativeFunctions.h

{-# LANGUAGE DataKinds #-}
{-# LANGUAGE PolyKinds #-}
{-# LANGUAGE TemplateHaskell #-}
{-# LANGUAGE QuasiQuotes #-}
{-# LANGUAGE ScopedTypeVariables #-}
{-# LANGUAGE OverloadedStrings #-}

module Aten.NativeFunctions.Dispatch.Cuda where

import qualified Language.C.Inline.Cpp as C
import qualified Language.C.Inline.Cpp.Exceptions as C
import qualified Language.C.Inline.Context as C
import qualified Language.C.Types as C
import qualified Data.Map as Map

import Foreign.C.String
import Foreign.C.Types
import Foreign
import Aten.NativeFunctions.Type

C.context $ C.cppCtx <> mempty { C.ctxTypesTable = typeTable }

C.include "<ATen/ATen.h>"


_cudnn_ctc_loss_ttllibb
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr (Tensor,Tensor))
_cudnn_ctc_loss_ttllibb _log_probs _targets _input_lengths _target_lengths _blank _deterministic _zero_infinity =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::_cudnn_ctc_loss(
    *$(at::Tensor* _log_probs)
  , *$(at::Tensor* _targets)
  , *$(at::IntArrayRef* _input_lengths)
  , *$(at::IntArrayRef* _target_lengths)
  , $(int _blank)
  , $(bool _deterministic)
  , $(bool _zero_infinity)));
  }|]

_cudnn_rnn_flatten_weight_liiiiibb
  :: Ptr TensorList
  -> CInt
  -> CInt
  -> CInt
  -> CInt
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
_cudnn_rnn_flatten_weight_liiiiibb _weight_arr _weight_stride0 _input_size _mode _hidden_size _num_layers _batch_first _bidirectional =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_cudnn_rnn_flatten_weight(
    *$(at::TensorList* _weight_arr)
  , $(int _weight_stride0)
  , $(int _input_size)
  , $(int _mode)
  , $(int _hidden_size)
  , $(int _num_layers)
  , $(bool _batch_first)
  , $(bool _bidirectional)));
  }|]

_cudnn_rnn_tlitttiiibfbblt
  :: Ptr Tensor
  -> Ptr TensorList
  -> CInt
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> CInt
  -> CInt
  -> CBool
  -> CFloat
  -> CBool
  -> CBool
  -> Ptr IntList
  -> Ptr Tensor
  -> IO (Ptr (Tensor,Tensor,Tensor,Tensor,Tensor))
_cudnn_rnn_tlitttiiibfbblt _input _weight _weight_stride0 _weight_buf _hx _cx _mode _hidden_size _num_layers _batch_first _dropout _train _bidirectional _batch_sizes _dropout_state =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor>(at::native::_cudnn_rnn(
    *$(at::Tensor* _input)
  , *$(at::TensorList* _weight)
  , $(int _weight_stride0)
  , *$(at::Tensor* _weight_buf)
  , *$(at::Tensor* _hx)
  , *$(at::Tensor* _cx)
  , $(int _mode)
  , $(int _hidden_size)
  , $(int _num_layers)
  , $(bool _batch_first)
  , $(float _dropout)
  , $(bool _train)
  , $(bool _bidirectional)
  , *$(at::IntArrayRef* _batch_sizes)
  , *$(at::Tensor* _dropout_state)));
  }|]

_cudnn_rnn_backward_tlitttttttiiibfbbltta
  :: Ptr Tensor
  -> Ptr TensorList
  -> CInt
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> CInt
  -> CInt
  -> CBool
  -> CFloat
  -> CBool
  -> CBool
  -> Ptr IntList
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr (StdArray CBool 4)
  -> IO (Ptr (Tensor,Tensor,Tensor,TensorList))
_cudnn_rnn_backward_tlitttttttiiibfbbltta _input _weight _weight_stride0 _weight_buf _hx _cx _output _grad_output _grad_hy _grad_cy _mode _hidden_size _num_layers _batch_first _dropout _train _bidirectional _batch_sizes _dropout_state _reserve _output_mask =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor,at::TensorList>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor,at::TensorList>(at::native::_cudnn_rnn_backward(
    *$(at::Tensor* _input)
  , *$(at::TensorList* _weight)
  , $(int _weight_stride0)
  , *$(at::Tensor* _weight_buf)
  , *$(at::Tensor* _hx)
  , *$(at::Tensor* _cx)
  , *$(at::Tensor* _output)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _grad_hy)
  , *$(at::Tensor* _grad_cy)
  , $(int _mode)
  , $(int _hidden_size)
  , $(int _num_layers)
  , $(bool _batch_first)
  , $(float _dropout)
  , $(bool _train)
  , $(bool _bidirectional)
  , *$(at::IntArrayRef* _batch_sizes)
  , *$(at::Tensor* _dropout_state)
  , *$(at::Tensor* _reserve)
  , *$(std::array<bool,4>* _output_mask)));
  }|]

_cudnn_init_dropout_state_fbio
  :: CFloat
  -> CBool
  -> CInt
  -> Ptr TensorOptions
  -> IO (Ptr Tensor)
_cudnn_init_dropout_state_fbio _dropout _train _dropout_seed _options =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_cudnn_init_dropout_state(
    $(float _dropout)
  , $(bool _train)
  , $(int _dropout_seed)
  , *$(at::TensorOptions* _options)));
  }|]

fused_dropout_cuda_tfp
  :: Ptr Tensor
  -> CFloat
  -> Ptr Generator
  -> IO (Ptr (Tensor,Tensor))
fused_dropout_cuda_tfp _self _p _generator =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::fused_dropout_cuda(
    *$(at::Tensor* _self)
  , $(float _p)
  , $(at::Generator * _generator)));
  }|]

masked_scale_cuda_ttf
  :: Ptr Tensor
  -> Ptr Tensor
  -> CFloat
  -> IO (Ptr Tensor)
masked_scale_cuda_ttf _self _mask _scale =
  [C.block| at::Tensor* { return new at::Tensor(at::native::masked_scale_cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _mask)
  , $(float _scale)));
  }|]

_abs__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_abs__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_abs__cuda(
    *$(at::Tensor* _self)));
  }|]

_acos__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_acos__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_acos__cuda(
    *$(at::Tensor* _self)));
  }|]

arange_cuda_out_Tsss
  :: Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
arange_cuda_out_Tsss _out _start _end _step =
  [C.block| at::Tensor* { return new at::Tensor(at::native::arange_cuda_out(
    *$(at::Tensor* _out)
  , *$(at::Scalar* _start)
  , *$(at::Scalar* _end)
  , *$(at::Scalar* _step)));
  }|]

_asin__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_asin__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_asin__cuda(
    *$(at::Tensor* _self)));
  }|]

_asin_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_asin_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_asin_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_atan__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_atan__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_atan__cuda(
    *$(at::Tensor* _self)));
  }|]

_atan_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_atan_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_atan_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

baddbmm_cuda_tttss
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
baddbmm_cuda_tttss _self _batch1 _batch2 _beta _alpha =
  [C.block| at::Tensor* { return new at::Tensor(at::native::baddbmm_cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _batch1)
  , *$(at::Tensor* _batch2)
  , *$(at::Scalar* _beta)
  , *$(at::Scalar* _alpha)));
  }|]

baddbmm__cuda_Tttss
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
baddbmm__cuda_Tttss _self _batch1 _batch2 _beta _alpha =
  [C.block| at::Tensor* { return new at::Tensor(at::native::baddbmm__cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _batch1)
  , *$(at::Tensor* _batch2)
  , *$(at::Scalar* _beta)
  , *$(at::Scalar* _alpha)));
  }|]

baddbmm_out_cuda_Ttttss
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
baddbmm_out_cuda_Ttttss _out _self _batch1 _batch2 _beta _alpha =
  [C.block| at::Tensor* { return new at::Tensor(at::native::baddbmm_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , *$(at::Tensor* _batch1)
  , *$(at::Tensor* _batch2)
  , *$(at::Scalar* _beta)
  , *$(at::Scalar* _alpha)));
  }|]

bernoulli_tensor_cuda__Ttp
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Generator
  -> IO (Ptr Tensor)
bernoulli_tensor_cuda__Ttp _self _p _generator =
  [C.block| at::Tensor* { return new at::Tensor(at::native::bernoulli_tensor_cuda_(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _p)
  , $(at::Generator * _generator)));
  }|]

bernoulli_scalar_cuda__Tfp
  :: Ptr Tensor
  -> CFloat
  -> Ptr Generator
  -> IO (Ptr Tensor)
bernoulli_scalar_cuda__Tfp _self _p _generator =
  [C.block| at::Tensor* { return new at::Tensor(at::native::bernoulli_scalar_cuda_(
    *$(at::Tensor* _self)
  , $(float _p)
  , $(at::Generator * _generator)));
  }|]

_bincount_cuda_tti
  :: Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> IO (Ptr Tensor)
_bincount_cuda_tti _self _weights _minlength =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_bincount_cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _weights)
  , $(int _minlength)));
  }|]

bmm_cuda_tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
bmm_cuda_tt _self _mat2 =
  [C.block| at::Tensor* { return new at::Tensor(at::native::bmm_cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _mat2)));
  }|]

bmm_out_cuda_Ttt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
bmm_out_cuda_Ttt _out _self _mat2 =
  [C.block| at::Tensor* { return new at::Tensor(at::native::bmm_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , *$(at::Tensor* _mat2)));
  }|]

_ceil__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_ceil__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_ceil__cuda(
    *$(at::Tensor* _self)));
  }|]

_ceil_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_ceil_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_ceil_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_clamp__cuda_Tss
  :: Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
_clamp__cuda_Tss _self _min _max =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_clamp__cuda(
    *$(at::Tensor* _self)
  , *$(at::Scalar* _min)
  , *$(at::Scalar* _max)));
  }|]

_clamp_out_cuda_Ttss
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
_clamp_out_cuda_Ttss _out _self _min _max =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_clamp_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , *$(at::Scalar* _min)
  , *$(at::Scalar* _max)));
  }|]

_clamp_max__cuda_Ts
  :: Ptr Tensor
  -> Ptr Scalar
  -> IO (Ptr Tensor)
_clamp_max__cuda_Ts _self _max =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_clamp_max__cuda(
    *$(at::Tensor* _self)
  , *$(at::Scalar* _max)));
  }|]

_clamp_max_out_cuda_Tts
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> IO (Ptr Tensor)
_clamp_max_out_cuda_Tts _out _self _max =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_clamp_max_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , *$(at::Scalar* _max)));
  }|]

_clamp_min__cuda_Ts
  :: Ptr Tensor
  -> Ptr Scalar
  -> IO (Ptr Tensor)
_clamp_min__cuda_Ts _self _min =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_clamp_min__cuda(
    *$(at::Tensor* _self)
  , *$(at::Scalar* _min)));
  }|]

_clamp_min_out_cuda_Tts
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> IO (Ptr Tensor)
_clamp_min_out_cuda_Tts _out _self _min =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_clamp_min_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , *$(at::Scalar* _min)));
  }|]

_s_copy__cuda_Ttb
  :: Ptr Tensor
  -> Ptr Tensor
  -> CBool
  -> IO (Ptr Tensor)
_s_copy__cuda_Ttb _self _src _non_blocking =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_s_copy__cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _src)
  , $(bool _non_blocking)));
  }|]

_s_copy_from_cuda_ttb
  :: Ptr Tensor
  -> Ptr Tensor
  -> CBool
  -> IO (Ptr Tensor)
_s_copy_from_cuda_ttb _self _dst _non_blocking =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_s_copy_from_cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _dst)
  , $(bool _non_blocking)));
  }|]

_cos__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_cos__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_cos__cuda(
    *$(at::Tensor* _self)));
  }|]

_cos_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_cos_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_cos_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_cosh__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_cosh__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_cosh__cuda(
    *$(at::Tensor* _self)));
  }|]

_cosh_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_cosh_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_cosh_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

cudnn_affine_grid_generator_forward_tiiii
  :: Ptr Tensor
  -> CInt
  -> CInt
  -> CInt
  -> CInt
  -> IO (Ptr Tensor)
cudnn_affine_grid_generator_forward_tiiii _theta _N _C _H _W =
  [C.block| at::Tensor* { return new at::Tensor(at::native::cudnn_affine_grid_generator_forward(
    *$(at::Tensor* _theta)
  , $(int _N)
  , $(int _C)
  , $(int _H)
  , $(int _W)));
  }|]

cudnn_affine_grid_generator_backward_tiiii
  :: Ptr Tensor
  -> CInt
  -> CInt
  -> CInt
  -> CInt
  -> IO (Ptr Tensor)
cudnn_affine_grid_generator_backward_tiiii _grad _N _C _H _W =
  [C.block| at::Tensor* { return new at::Tensor(at::native::cudnn_affine_grid_generator_backward(
    *$(at::Tensor* _grad)
  , $(int _N)
  , $(int _C)
  , $(int _H)
  , $(int _W)));
  }|]

cudnn_batch_norm_tttttbff
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CBool
  -> CFloat
  -> CFloat
  -> IO (Ptr (Tensor,Tensor,Tensor))
cudnn_batch_norm_tttttbff _input _weight _bias _running_mean _running_var _training _exponential_average_factor _epsilon =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::cudnn_batch_norm(
    *$(at::Tensor* _input)
  , *$(at::Tensor* _weight)
  , *$(at::Tensor* _bias)
  , *$(at::Tensor* _running_mean)
  , *$(at::Tensor* _running_var)
  , $(bool _training)
  , $(float _exponential_average_factor)
  , $(float _epsilon)));
  }|]

cudnn_batch_norm_backward_tttttttf
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CFloat
  -> IO (Ptr (Tensor,Tensor,Tensor))
cudnn_batch_norm_backward_tttttttf _input _grad_output _weight _running_mean _running_var _save_mean _save_var _epsilon =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::cudnn_batch_norm_backward(
    *$(at::Tensor* _input)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _weight)
  , *$(at::Tensor* _running_mean)
  , *$(at::Tensor* _running_var)
  , *$(at::Tensor* _save_mean)
  , *$(at::Tensor* _save_var)
  , $(float _epsilon)));
  }|]

cudnn_convolution_tttlllibb
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
cudnn_convolution_tttlllibb _self _weight _bias _padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::cudnn_convolution(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _weight)
  , *$(at::Tensor* _bias)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

cudnn_convolution_backward_input_lttlllibb
  :: Ptr IntList
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
cudnn_convolution_backward_input_lttlllibb _self_size _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::cudnn_convolution_backward_input(
    *$(at::IntArrayRef* _self_size)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _weight)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

cudnn_convolution_backward_tttlllibba
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> Ptr (StdArray CBool 3)
  -> IO (Ptr (Tensor,Tensor,Tensor))
cudnn_convolution_backward_tttlllibba _self _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic _output_mask =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::cudnn_convolution_backward(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _weight)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)
  , *$(std::array<bool,3>* _output_mask)));
  }|]

cudnn_convolution_backward_bias_t
  :: Ptr Tensor
  -> IO (Ptr Tensor)
cudnn_convolution_backward_bias_t _grad_output =
  [C.block| at::Tensor* { return new at::Tensor(at::native::cudnn_convolution_backward_bias(
    *$(at::Tensor* _grad_output)));
  }|]

cudnn_convolution_backward_weight_lttlllibb
  :: Ptr IntList
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
cudnn_convolution_backward_weight_lttlllibb _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::cudnn_convolution_backward_weight(
    *$(at::IntArrayRef* _weight_size)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

cudnn_convolution_transpose_tttllllibb
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
cudnn_convolution_transpose_tttllllibb _self _weight _bias _padding _output_padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::cudnn_convolution_transpose(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _weight)
  , *$(at::Tensor* _bias)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _output_padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

cudnn_convolution_transpose_backward_tttllllibba
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> Ptr (StdArray CBool 3)
  -> IO (Ptr (Tensor,Tensor,Tensor))
cudnn_convolution_transpose_backward_tttllllibba _self _grad_output _weight _padding _output_padding _stride _dilation _groups _benchmark _deterministic _output_mask =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::cudnn_convolution_transpose_backward(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _weight)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _output_padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)
  , *$(std::array<bool,3>* _output_mask)));
  }|]

cudnn_convolution_transpose_backward_input_ttlllibb
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
cudnn_convolution_transpose_backward_input_ttlllibb _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::cudnn_convolution_transpose_backward_input(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _weight)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

cudnn_convolution_transpose_backward_weight_lttlllibb
  :: Ptr IntList
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
cudnn_convolution_transpose_backward_weight_lttlllibb _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::cudnn_convolution_transpose_backward_weight(
    *$(at::IntArrayRef* _weight_size)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

cudnn_grid_sampler_forward_tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
cudnn_grid_sampler_forward_tt _self _grid =
  [C.block| at::Tensor* { return new at::Tensor(at::native::cudnn_grid_sampler_forward(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _grid)));
  }|]

cudnn_grid_sampler_backward_ttt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr (Tensor,Tensor))
cudnn_grid_sampler_backward_ttt _self _grid _grad_output =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::cudnn_grid_sampler_backward(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _grid)
  , *$(at::Tensor* _grad_output)));
  }|]

ctc_loss_gpu_ttllib
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> IO (Ptr (Tensor,Tensor))
ctc_loss_gpu_ttllib _log_probs _targets _input_lengths _target_lengths _blank _zero_infinity =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::ctc_loss_gpu(
    *$(at::Tensor* _log_probs)
  , *$(at::Tensor* _targets)
  , *$(at::IntArrayRef* _input_lengths)
  , *$(at::IntArrayRef* _target_lengths)
  , $(int _blank)
  , $(bool _zero_infinity)));
  }|]

ctc_loss_backward_gpu_tttllttib
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> CBool
  -> IO (Ptr Tensor)
ctc_loss_backward_gpu_tttllttib _grad _log_probs _targets _input_lengths _target_lengths _neg_log_likelihood _log_alpha _blank _zero_infinity =
  [C.block| at::Tensor* { return new at::Tensor(at::native::ctc_loss_backward_gpu(
    *$(at::Tensor* _grad)
  , *$(at::Tensor* _log_probs)
  , *$(at::Tensor* _targets)
  , *$(at::IntArrayRef* _input_lengths)
  , *$(at::IntArrayRef* _target_lengths)
  , *$(at::Tensor* _neg_log_likelihood)
  , *$(at::Tensor* _log_alpha)
  , $(int _blank)
  , $(bool _zero_infinity)));
  }|]

embedding_dense_backward_cuda_ttiib
  :: Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> CInt
  -> CBool
  -> IO (Ptr Tensor)
embedding_dense_backward_cuda_ttiib _grad _indices _num_weights _padding_idx _scale_grad_by_freq =
  [C.block| at::Tensor* { return new at::Tensor(at::native::embedding_dense_backward_cuda(
    *$(at::Tensor* _grad)
  , *$(at::Tensor* _indices)
  , $(int _num_weights)
  , $(int _padding_idx)
  , $(bool _scale_grad_by_freq)));
  }|]

embedding_renorm_cuda__Ttff
  :: Ptr Tensor
  -> Ptr Tensor
  -> CFloat
  -> CFloat
  -> IO (Ptr Tensor)
embedding_renorm_cuda__Ttff _self _indices _max_norm _norm_type =
  [C.block| at::Tensor* { return new at::Tensor(at::native::embedding_renorm_cuda_(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _indices)
  , $(float _max_norm)
  , $(float _norm_type)));
  }|]

_embedding_bag_cuda_tttbib
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CBool
  -> CInt
  -> CBool
  -> IO (Ptr (Tensor,Tensor,Tensor,Tensor))
_embedding_bag_cuda_tttbib _weight _indices _offsets _scale_grad_by_freq _mode _sparse =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor>(at::native::_embedding_bag_cuda(
    *$(at::Tensor* _weight)
  , *$(at::Tensor* _indices)
  , *$(at::Tensor* _offsets)
  , $(bool _scale_grad_by_freq)
  , $(int _mode)
  , $(bool _sparse)));
  }|]

_embedding_bag_dense_backward_cuda_ttttttibi
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> CBool
  -> CInt
  -> IO (Ptr Tensor)
_embedding_bag_dense_backward_cuda_ttttttibi _grad _indices _offsets _offset2bag _bag_size _maximum_indices _num_weights _scale_grad_by_freq _mode =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_embedding_bag_dense_backward_cuda(
    *$(at::Tensor* _grad)
  , *$(at::Tensor* _indices)
  , *$(at::Tensor* _offsets)
  , *$(at::Tensor* _offset2bag)
  , *$(at::Tensor* _bag_size)
  , *$(at::Tensor* _maximum_indices)
  , $(int _num_weights)
  , $(bool _scale_grad_by_freq)
  , $(int _mode)));
  }|]

empty_cuda_lo
  :: Ptr IntList
  -> Ptr TensorOptions
  -> IO (Ptr Tensor)
empty_cuda_lo _size _options =
  [C.block| at::Tensor* { return new at::Tensor(at::native::empty_cuda(
    *$(at::IntArrayRef* _size)
  , *$(at::TensorOptions* _options)));
  }|]

resize_cuda__Tl
  :: Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
resize_cuda__Tl _self _size =
  [C.block| at::Tensor* { return new at::Tensor(at::native::resize_cuda_(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _size)));
  }|]

empty_strided_cuda_llo
  :: Ptr IntList
  -> Ptr IntList
  -> Ptr TensorOptions
  -> IO (Ptr Tensor)
empty_strided_cuda_llo _size _stride _options =
  [C.block| at::Tensor* { return new at::Tensor(at::native::empty_strided_cuda(
    *$(at::IntArrayRef* _size)
  , *$(at::IntArrayRef* _stride)
  , *$(at::TensorOptions* _options)));
  }|]

_erf__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_erf__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_erf__cuda(
    *$(at::Tensor* _self)));
  }|]

_erf_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_erf_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_erf_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_erfc__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_erfc__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_erfc__cuda(
    *$(at::Tensor* _self)));
  }|]

_erfc_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_erfc_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_erfc_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_exp__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_exp__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_exp__cuda(
    *$(at::Tensor* _self)));
  }|]

_exp_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_exp_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_exp_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_expm1__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_expm1__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_expm1__cuda(
    *$(at::Tensor* _self)));
  }|]

_expm1_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_expm1_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_expm1_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

eye_out_cuda_Ti
  :: Ptr Tensor
  -> CInt
  -> IO (Ptr Tensor)
eye_out_cuda_Ti _out _n =
  [C.block| at::Tensor* { return new at::Tensor(at::native::eye_out_cuda(
    *$(at::Tensor* _out)
  , $(int _n)));
  }|]

eye_out_cuda_Tii
  :: Ptr Tensor
  -> CInt
  -> CInt
  -> IO (Ptr Tensor)
eye_out_cuda_Tii _out _n _m =
  [C.block| at::Tensor* { return new at::Tensor(at::native::eye_out_cuda(
    *$(at::Tensor* _out)
  , $(int _n)
  , $(int _m)));
  }|]

_floor__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_floor__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_floor__cuda(
    *$(at::Tensor* _self)));
  }|]

_floor_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_floor_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_floor_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

grid_sampler_2d_cuda_ttii
  :: Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> CInt
  -> IO (Ptr Tensor)
grid_sampler_2d_cuda_ttii _input _grid _interpolation_mode _padding_mode =
  [C.block| at::Tensor* { return new at::Tensor(at::native::grid_sampler_2d_cuda(
    *$(at::Tensor* _input)
  , *$(at::Tensor* _grid)
  , $(int _interpolation_mode)
  , $(int _padding_mode)));
  }|]

grid_sampler_2d_backward_cuda_tttii
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> CInt
  -> IO (Ptr (Tensor,Tensor))
grid_sampler_2d_backward_cuda_tttii _grad_output _input _grid _interpolation_mode _padding_mode =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::grid_sampler_2d_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _input)
  , *$(at::Tensor* _grid)
  , $(int _interpolation_mode)
  , $(int _padding_mode)));
  }|]

grid_sampler_3d_cuda_ttii
  :: Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> CInt
  -> IO (Ptr Tensor)
grid_sampler_3d_cuda_ttii _input _grid _interpolation_mode _padding_mode =
  [C.block| at::Tensor* { return new at::Tensor(at::native::grid_sampler_3d_cuda(
    *$(at::Tensor* _input)
  , *$(at::Tensor* _grid)
  , $(int _interpolation_mode)
  , $(int _padding_mode)));
  }|]

grid_sampler_3d_backward_cuda_tttii
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> CInt
  -> IO (Ptr (Tensor,Tensor))
grid_sampler_3d_backward_cuda_tttii _grad_output _input _grid _interpolation_mode _padding_mode =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::grid_sampler_3d_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _input)
  , *$(at::Tensor* _grid)
  , $(int _interpolation_mode)
  , $(int _padding_mode)));
  }|]

_gesv_helper_cuda_tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr (Tensor,Tensor))
_gesv_helper_cuda_tt _self _A =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::_gesv_helper_cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _A)));
  }|]

_fft_cufft_tibbblbbl
  :: Ptr Tensor
  -> CInt
  -> CBool
  -> CBool
  -> CBool
  -> Ptr IntList
  -> CBool
  -> CBool
  -> Ptr IntList
  -> IO (Ptr Tensor)
_fft_cufft_tibbblbbl _self _signal_ndim _complex_input _complex_output _inverse _checked_signal_sizes _normalized _onesided _output_sizes =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_fft_cufft(
    *$(at::Tensor* _self)
  , $(int _signal_ndim)
  , $(bool _complex_input)
  , $(bool _complex_output)
  , $(bool _inverse)
  , *$(at::IntArrayRef* _checked_signal_sizes)
  , $(bool _normalized)
  , $(bool _onesided)
  , *$(at::IntArrayRef* _output_sizes)));
  }|]

_inverse_helper_cuda_t
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_inverse_helper_cuda_t _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_inverse_helper_cuda(
    *$(at::Tensor* _self)));
  }|]

kl_div_backward_cuda_ttti
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> IO (Ptr Tensor)
kl_div_backward_cuda_ttti _grad_output _self _target _reduction =
  [C.block| at::Tensor* { return new at::Tensor(at::native::kl_div_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::Tensor* _target)
  , $(int _reduction)));
  }|]

linspace_cuda_out_Tssi
  :: Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> CInt
  -> IO (Ptr Tensor)
linspace_cuda_out_Tssi _out _start _end _steps =
  [C.block| at::Tensor* { return new at::Tensor(at::native::linspace_cuda_out(
    *$(at::Tensor* _out)
  , *$(at::Scalar* _start)
  , *$(at::Scalar* _end)
  , $(int _steps)));
  }|]

_log__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_log__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_log__cuda(
    *$(at::Tensor* _self)));
  }|]

_log_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_log_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_log_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_log10__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_log10__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_log10__cuda(
    *$(at::Tensor* _self)));
  }|]

_log10_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_log10_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_log10_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_log1p__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_log1p__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_log1p__cuda(
    *$(at::Tensor* _self)));
  }|]

_log1p_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_log1p_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_log1p_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_log2__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_log2__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_log2__cuda(
    *$(at::Tensor* _self)));
  }|]

_log2_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_log2_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_log2_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

logspace_cuda_out_Tssi
  :: Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> CInt
  -> IO (Ptr Tensor)
logspace_cuda_out_Tssi _out _start _end _steps =
  [C.block| at::Tensor* { return new at::Tensor(at::native::logspace_cuda_out(
    *$(at::Tensor* _out)
  , *$(at::Scalar* _start)
  , *$(at::Scalar* _end)
  , $(int _steps)));
  }|]

log_softmax_cuda_tib
  :: Ptr Tensor
  -> CInt
  -> CBool
  -> IO (Ptr Tensor)
log_softmax_cuda_tib _self _dim _half_to_float =
  [C.block| at::Tensor* { return new at::Tensor(at::native::log_softmax_cuda(
    *$(at::Tensor* _self)
  , $(int _dim)
  , $(bool _half_to_float)));
  }|]

log_softmax_backward_cuda_ttit
  :: Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> Ptr Tensor
  -> IO (Ptr Tensor)
log_softmax_backward_cuda_ttit _grad_output _output _dim _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::log_softmax_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _output)
  , $(int _dim)
  , *$(at::Tensor* _self)));
  }|]

miopen_batch_norm_tttttbff
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CBool
  -> CFloat
  -> CFloat
  -> IO (Ptr (Tensor,Tensor,Tensor))
miopen_batch_norm_tttttbff _input _weight _bias _running_mean _running_var _training _exponential_average_factor _epsilon =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::miopen_batch_norm(
    *$(at::Tensor* _input)
  , *$(at::Tensor* _weight)
  , *$(at::Tensor* _bias)
  , *$(at::Tensor* _running_mean)
  , *$(at::Tensor* _running_var)
  , $(bool _training)
  , $(float _exponential_average_factor)
  , $(float _epsilon)));
  }|]

miopen_batch_norm_backward_tttttttf
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CFloat
  -> IO (Ptr (Tensor,Tensor,Tensor))
miopen_batch_norm_backward_tttttttf _input _grad_output _weight _running_mean _running_var _save_mean _save_var _epsilon =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::miopen_batch_norm_backward(
    *$(at::Tensor* _input)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _weight)
  , *$(at::Tensor* _running_mean)
  , *$(at::Tensor* _running_var)
  , *$(at::Tensor* _save_mean)
  , *$(at::Tensor* _save_var)
  , $(float _epsilon)));
  }|]

miopen_convolution_tttlllibb
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
miopen_convolution_tttlllibb _self _weight _bias _padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::miopen_convolution(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _weight)
  , *$(at::Tensor* _bias)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

miopen_convolution_backward_input_lttlllibb
  :: Ptr IntList
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
miopen_convolution_backward_input_lttlllibb _self_size _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::miopen_convolution_backward_input(
    *$(at::IntArrayRef* _self_size)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _weight)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

miopen_convolution_backward_tttlllibba
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> Ptr (StdArray CBool 3)
  -> IO (Ptr (Tensor,Tensor,Tensor))
miopen_convolution_backward_tttlllibba _self _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic _output_mask =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::miopen_convolution_backward(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _weight)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)
  , *$(std::array<bool,3>* _output_mask)));
  }|]

miopen_convolution_backward_bias_t
  :: Ptr Tensor
  -> IO (Ptr Tensor)
miopen_convolution_backward_bias_t _grad_output =
  [C.block| at::Tensor* { return new at::Tensor(at::native::miopen_convolution_backward_bias(
    *$(at::Tensor* _grad_output)));
  }|]

miopen_convolution_backward_weight_lttlllibb
  :: Ptr IntList
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
miopen_convolution_backward_weight_lttlllibb _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::miopen_convolution_backward_weight(
    *$(at::IntArrayRef* _weight_size)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

miopen_convolution_transpose_tttllllibb
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
miopen_convolution_transpose_tttllllibb _self _weight _bias _padding _output_padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::miopen_convolution_transpose(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _weight)
  , *$(at::Tensor* _bias)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _output_padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

miopen_convolution_transpose_backward_tttllllibba
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> Ptr (StdArray CBool 3)
  -> IO (Ptr (Tensor,Tensor,Tensor))
miopen_convolution_transpose_backward_tttllllibba _self _grad_output _weight _padding _output_padding _stride _dilation _groups _benchmark _deterministic _output_mask =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::miopen_convolution_transpose_backward(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _weight)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _output_padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)
  , *$(std::array<bool,3>* _output_mask)));
  }|]

miopen_convolution_transpose_backward_input_ttlllibb
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
miopen_convolution_transpose_backward_input_ttlllibb _grad_output _weight _padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::miopen_convolution_transpose_backward_input(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _weight)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

miopen_convolution_transpose_backward_weight_lttlllibb
  :: Ptr IntList
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr IntList
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr Tensor)
miopen_convolution_transpose_backward_weight_lttlllibb _weight_size _grad_output _self _padding _stride _dilation _groups _benchmark _deterministic =
  [C.block| at::Tensor* { return new at::Tensor(at::native::miopen_convolution_transpose_backward_weight(
    *$(at::IntArrayRef* _weight_size)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)
  , *$(at::IntArrayRef* _stride)
  , *$(at::IntArrayRef* _dilation)
  , $(int _groups)
  , $(bool _benchmark)
  , $(bool _deterministic)));
  }|]

narrow_copy_dense_tiii
  :: Ptr Tensor
  -> CInt
  -> CInt
  -> CInt
  -> IO (Ptr Tensor)
narrow_copy_dense_tiii _self _dim _start _length =
  [C.block| at::Tensor* { return new at::Tensor(at::native::narrow_copy_dense(
    *$(at::Tensor* _self)
  , $(int _dim)
  , $(int _start)
  , $(int _length)));
  }|]

batch_norm_cuda_tttttbff
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CBool
  -> CFloat
  -> CFloat
  -> IO (Ptr (Tensor,Tensor,Tensor))
batch_norm_cuda_tttttbff _input _weight _bias _running_mean _running_var _training _momentum _eps =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::batch_norm_cuda(
    *$(at::Tensor* _input)
  , *$(at::Tensor* _weight)
  , *$(at::Tensor* _bias)
  , *$(at::Tensor* _running_mean)
  , *$(at::Tensor* _running_var)
  , $(bool _training)
  , $(float _momentum)
  , $(float _eps)));
  }|]

batch_norm_backward_cuda_tttttttbfa
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CBool
  -> CFloat
  -> Ptr (StdArray CBool 3)
  -> IO (Ptr (Tensor,Tensor,Tensor))
batch_norm_backward_cuda_tttttttbfa _grad_out _input _weight _running_mean _running_var _save_mean _save_invstd _train _eps _output_mask =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::batch_norm_backward_cuda(
    *$(at::Tensor* _grad_out)
  , *$(at::Tensor* _input)
  , *$(at::Tensor* _weight)
  , *$(at::Tensor* _running_mean)
  , *$(at::Tensor* _running_var)
  , *$(at::Tensor* _save_mean)
  , *$(at::Tensor* _save_invstd)
  , $(bool _train)
  , $(float _eps)
  , *$(std::array<bool,3>* _output_mask)));
  }|]

batch_norm_update_stats_cuda_tttf
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CFloat
  -> IO (Ptr (Tensor,Tensor))
batch_norm_update_stats_cuda_tttf _input _running_mean _running_var _momentum =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::batch_norm_update_stats_cuda(
    *$(at::Tensor* _input)
  , *$(at::Tensor* _running_mean)
  , *$(at::Tensor* _running_var)
  , $(float _momentum)));
  }|]

randperm_out_cuda_Tip
  :: Ptr Tensor
  -> CInt
  -> Ptr Generator
  -> IO (Ptr Tensor)
randperm_out_cuda_Tip _out _n _generator =
  [C.block| at::Tensor* { return new at::Tensor(at::native::randperm_out_cuda(
    *$(at::Tensor* _out)
  , $(int _n)
  , $(at::Generator * _generator)));
  }|]

range_cuda_out_Tsss
  :: Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
range_cuda_out_Tsss _out _start _end _step =
  [C.block| at::Tensor* { return new at::Tensor(at::native::range_cuda_out(
    *$(at::Tensor* _out)
  , *$(at::Scalar* _start)
  , *$(at::Scalar* _end)
  , *$(at::Scalar* _step)));
  }|]

_round__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_round__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_round__cuda(
    *$(at::Tensor* _self)));
  }|]

_round_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_round_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_round_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

prelu_cuda_tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
prelu_cuda_tt _self _weight =
  [C.block| at::Tensor* { return new at::Tensor(at::native::prelu_cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _weight)));
  }|]

prelu_backward_cuda_ttt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr (Tensor,Tensor))
prelu_backward_cuda_ttt _grad_output _self _weight =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::prelu_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::Tensor* _weight)));
  }|]

hardshrink_cuda_ts
  :: Ptr Tensor
  -> Ptr Scalar
  -> IO (Ptr Tensor)
hardshrink_cuda_ts _self _lambd =
  [C.block| at::Tensor* { return new at::Tensor(at::native::hardshrink_cuda(
    *$(at::Tensor* _self)
  , *$(at::Scalar* _lambd)));
  }|]

hardshrink_backward_cuda_tts
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> IO (Ptr Tensor)
hardshrink_backward_cuda_tts _grad_out _self _lambd =
  [C.block| at::Tensor* { return new at::Tensor(at::native::hardshrink_backward_cuda(
    *$(at::Tensor* _grad_out)
  , *$(at::Tensor* _self)
  , *$(at::Scalar* _lambd)));
  }|]

_rsqrt__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_rsqrt__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_rsqrt__cuda(
    *$(at::Tensor* _self)));
  }|]

_rsqrt_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_rsqrt_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_rsqrt_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_sigmoid__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_sigmoid__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_sigmoid__cuda(
    *$(at::Tensor* _self)));
  }|]

_sigmoid_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_sigmoid_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_sigmoid_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_sin__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_sin__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_sin__cuda(
    *$(at::Tensor* _self)));
  }|]

_sin_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_sin_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_sin_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_sinh__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_sinh__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_sinh__cuda(
    *$(at::Tensor* _self)));
  }|]

_sinh_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_sinh_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_sinh_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

softmax_cuda_tib
  :: Ptr Tensor
  -> CInt
  -> CBool
  -> IO (Ptr Tensor)
softmax_cuda_tib _self _dim _half_to_float =
  [C.block| at::Tensor* { return new at::Tensor(at::native::softmax_cuda(
    *$(at::Tensor* _self)
  , $(int _dim)
  , $(bool _half_to_float)));
  }|]

softmax_backward_cuda_ttit
  :: Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> Ptr Tensor
  -> IO (Ptr Tensor)
softmax_backward_cuda_ttit _grad_output _output _dim _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::softmax_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _output)
  , $(int _dim)
  , *$(at::Tensor* _self)));
  }|]

add_out_dense_sparse_cuda_Ttrs
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr SparseTensorRef
  -> Ptr Scalar
  -> IO (Ptr Tensor)
add_out_dense_sparse_cuda_Ttrs _out _self _other _alpha =
  [C.block| at::Tensor* { return new at::Tensor(at::native::add_out_dense_sparse_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , *$(at::SparseTensorRef* _other)
  , *$(at::Scalar* _alpha)));
  }|]

_sspaddmm_out_only_sparse_cuda_Ttttss
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
_sspaddmm_out_only_sparse_cuda_Ttttss _out _self _mat1 _mat2 _beta _alpha =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_sspaddmm_out_only_sparse_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , *$(at::Tensor* _mat1)
  , *$(at::Tensor* _mat2)
  , *$(at::Scalar* _beta)
  , *$(at::Scalar* _alpha)));
  }|]

_sqrt__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_sqrt__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_sqrt__cuda(
    *$(at::Tensor* _self)));
  }|]

_sqrt_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_sqrt_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_sqrt_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_tan__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_tan__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_tan__cuda(
    *$(at::Tensor* _self)));
  }|]

_tan_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_tan_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_tan_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_tanh__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_tanh__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_tanh__cuda(
    *$(at::Tensor* _self)));
  }|]

_tanh_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_tanh_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_tanh_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

flip_cuda_tl
  :: Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
flip_cuda_tl _self _dims =
  [C.block| at::Tensor* { return new at::Tensor(at::native::flip_cuda(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _dims)));
  }|]

roll_cuda_tll
  :: Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> IO (Ptr Tensor)
roll_cuda_tll _self _shifts _dims =
  [C.block| at::Tensor* { return new at::Tensor(at::native::roll_cuda(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _shifts)
  , *$(at::IntArrayRef* _dims)));
  }|]

_trunc__cuda_T
  :: Ptr Tensor
  -> IO (Ptr Tensor)
_trunc__cuda_T _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_trunc__cuda(
    *$(at::Tensor* _self)));
  }|]

_trunc_out_cuda_Tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_trunc_out_cuda_Tt _out _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_trunc_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)));
  }|]

_unique_cuda_tbb
  :: Ptr Tensor
  -> CBool
  -> CBool
  -> IO (Ptr (Tensor,Tensor))
_unique_cuda_tbb _self _sorted _return_inverse =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::_unique_cuda(
    *$(at::Tensor* _self)
  , $(bool _sorted)
  , $(bool _return_inverse)));
  }|]

_unique_dim_cuda_tibb
  :: Ptr Tensor
  -> CInt
  -> CBool
  -> CBool
  -> IO (Ptr (Tensor,Tensor))
_unique_dim_cuda_tibb _self _dim _sorted _return_inverse =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::_unique_dim_cuda(
    *$(at::Tensor* _self)
  , $(int _dim)
  , $(bool _sorted)
  , $(bool _return_inverse)));
  }|]

_s_where_cuda_ttt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_s_where_cuda_ttt _condition _self _other =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_s_where_cuda(
    *$(at::Tensor* _condition)
  , *$(at::Tensor* _self)
  , *$(at::Tensor* _other)));
  }|]

weight_norm_cuda_tti
  :: Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> IO (Ptr (Tensor,Tensor))
weight_norm_cuda_tti _v _g _dim =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::weight_norm_cuda(
    *$(at::Tensor* _v)
  , *$(at::Tensor* _g)
  , $(int _dim)));
  }|]

weight_norm_cuda_backward_tttti
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> IO (Ptr (Tensor,Tensor))
weight_norm_cuda_backward_tttti _grad_w _saved_v _saved_g _saved_norms _dim =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::weight_norm_cuda_backward(
    *$(at::Tensor* _grad_w)
  , *$(at::Tensor* _saved_v)
  , *$(at::Tensor* _saved_g)
  , *$(at::Tensor* _saved_norms)
  , $(int _dim)));
  }|]

_standard_gamma_grad_cuda_tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
_standard_gamma_grad_cuda_tt _self _output =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_standard_gamma_grad_cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _output)));
  }|]

_s_gamma_cuda_tp
  :: Ptr Tensor
  -> Ptr Generator
  -> IO (Ptr Tensor)
_s_gamma_cuda_tp _self _generator =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_s_gamma_cuda(
    *$(at::Tensor* _self)
  , $(at::Generator * _generator)));
  }|]

_s_poisson_cuda_tp
  :: Ptr Tensor
  -> Ptr Generator
  -> IO (Ptr Tensor)
_s_poisson_cuda_tp _self _generator =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_s_poisson_cuda(
    *$(at::Tensor* _self)
  , $(at::Generator * _generator)));
  }|]

s_addmm_out_sparse_dense_cuda_Ttttss
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
s_addmm_out_sparse_dense_cuda_Ttttss _out _self _mat1 _mat2 _beta _alpha =
  [C.block| at::Tensor* { return new at::Tensor(at::native::s_addmm_out_sparse_dense_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , *$(at::Tensor* _mat1)
  , *$(at::Tensor* _mat2)
  , *$(at::Scalar* _beta)
  , *$(at::Scalar* _alpha)));
  }|]

s_addmm_sparse_dense_cuda_tttss
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
s_addmm_sparse_dense_cuda_tttss _self _mat1 _mat2 _beta _alpha =
  [C.block| at::Tensor* { return new at::Tensor(at::native::s_addmm_sparse_dense_cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _mat1)
  , *$(at::Tensor* _mat2)
  , *$(at::Scalar* _beta)
  , *$(at::Scalar* _alpha)));
  }|]

s_addmm_sparse_dense_cuda__Tttss
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
s_addmm_sparse_dense_cuda__Tttss _self _mat1 _mat2 _beta _alpha =
  [C.block| at::Tensor* { return new at::Tensor(at::native::s_addmm_sparse_dense_cuda_(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _mat1)
  , *$(at::Tensor* _mat2)
  , *$(at::Scalar* _beta)
  , *$(at::Scalar* _alpha)));
  }|]

sparse_mask_cuda_tr
  :: Ptr Tensor
  -> Ptr SparseTensorRef
  -> IO (Ptr Tensor)
sparse_mask_cuda_tr _self _mask =
  [C.block| at::Tensor* { return new at::Tensor(at::native::sparse_mask_cuda(
    *$(at::Tensor* _self)
  , *$(at::SparseTensorRef* _mask)));
  }|]

dense_to_sparse_ti
  :: Ptr Tensor
  -> CInt
  -> IO (Ptr Tensor)
dense_to_sparse_ti _self _sparse_dim =
  [C.block| at::Tensor* { return new at::Tensor(at::native::dense_to_sparse(
    *$(at::Tensor* _self)
  , $(int _sparse_dim)));
  }|]

dense_to_sparse_t
  :: Ptr Tensor
  -> IO (Ptr Tensor)
dense_to_sparse_t _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::dense_to_sparse(
    *$(at::Tensor* _self)));
  }|]

_local_scalar_dense_cuda_t
  :: Ptr Tensor
  -> IO (Ptr Scalar)
_local_scalar_dense_cuda_t _self =
  [C.block| at::Scalar* { return new at::Scalar(at::native::_local_scalar_dense_cuda(
    *$(at::Tensor* _self)));
  }|]

_thnn_fused_lstm_cell_cuda_ttttt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr (Tensor,Tensor,Tensor))
_thnn_fused_lstm_cell_cuda_ttttt _input_gates _hidden_gates _cx _input_bias _hidden_bias =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor>(at::native::_thnn_fused_lstm_cell_cuda(
    *$(at::Tensor* _input_gates)
  , *$(at::Tensor* _hidden_gates)
  , *$(at::Tensor* _cx)
  , *$(at::Tensor* _input_bias)
  , *$(at::Tensor* _hidden_bias)));
  }|]

_thnn_fused_lstm_cell_backward_cuda_tttttb
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> CBool
  -> IO (Ptr (Tensor,Tensor,Tensor,Tensor,Tensor))
_thnn_fused_lstm_cell_backward_cuda_tttttb _grad_hy _grad_cy _cx _cy _workspace _has_bias =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor>(at::native::_thnn_fused_lstm_cell_backward_cuda(
    *$(at::Tensor* _grad_hy)
  , *$(at::Tensor* _grad_cy)
  , *$(at::Tensor* _cx)
  , *$(at::Tensor* _cy)
  , *$(at::Tensor* _workspace)
  , $(bool _has_bias)));
  }|]

_thnn_fused_gru_cell_cuda_ttttt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr (Tensor,Tensor))
_thnn_fused_gru_cell_cuda_ttttt _input_gates _hidden_gates _hx _input_bias _hidden_bias =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::_thnn_fused_gru_cell_cuda(
    *$(at::Tensor* _input_gates)
  , *$(at::Tensor* _hidden_gates)
  , *$(at::Tensor* _hx)
  , *$(at::Tensor* _input_bias)
  , *$(at::Tensor* _hidden_bias)));
  }|]

_thnn_fused_gru_cell_backward_cuda_ttb
  :: Ptr Tensor
  -> Ptr Tensor
  -> CBool
  -> IO (Ptr (Tensor,Tensor,Tensor,Tensor,Tensor))
_thnn_fused_gru_cell_backward_cuda_ttb _grad_hy _workspace _has_bias =
  [C.block| std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor,at::Tensor,at::Tensor,at::Tensor>(at::native::_thnn_fused_gru_cell_backward_cuda(
    *$(at::Tensor* _grad_hy)
  , *$(at::Tensor* _workspace)
  , $(bool _has_bias)));
  }|]

tril_cuda__Ti
  :: Ptr Tensor
  -> CInt
  -> IO (Ptr Tensor)
tril_cuda__Ti _self _diagonal =
  [C.block| at::Tensor* { return new at::Tensor(at::native::tril_cuda_(
    *$(at::Tensor* _self)
  , $(int _diagonal)));
  }|]

triu_cuda__Ti
  :: Ptr Tensor
  -> CInt
  -> IO (Ptr Tensor)
triu_cuda__Ti _self _diagonal =
  [C.block| at::Tensor* { return new at::Tensor(at::native::triu_cuda_(
    *$(at::Tensor* _self)
  , $(int _diagonal)));
  }|]

triu_cuda_out_Tti
  :: Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> IO (Ptr Tensor)
triu_cuda_out_Tti _out _self _diagonal =
  [C.block| at::Tensor* { return new at::Tensor(at::native::triu_cuda_out(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , $(int _diagonal)));
  }|]

tril_cuda_out_Tti
  :: Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> IO (Ptr Tensor)
tril_cuda_out_Tti _out _self _diagonal =
  [C.block| at::Tensor* { return new at::Tensor(at::native::tril_cuda_out(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , $(int _diagonal)));
  }|]

tril_indices_cuda_iiio
  :: CInt
  -> CInt
  -> CInt
  -> Ptr TensorOptions
  -> IO (Ptr Tensor)
tril_indices_cuda_iiio _row _col _offset _options =
  [C.block| at::Tensor* { return new at::Tensor(at::native::tril_indices_cuda(
    $(int _row)
  , $(int _col)
  , $(int _offset)
  , *$(at::TensorOptions* _options)));
  }|]

triu_indices_cuda_iiio
  :: CInt
  -> CInt
  -> CInt
  -> Ptr TensorOptions
  -> IO (Ptr Tensor)
triu_indices_cuda_iiio _row _col _offset _options =
  [C.block| at::Tensor* { return new at::Tensor(at::native::triu_indices_cuda(
    $(int _row)
  , $(int _col)
  , $(int _offset)
  , *$(at::TensorOptions* _options)));
  }|]

_cholesky_helper_cuda_tb
  :: Ptr Tensor
  -> CBool
  -> IO (Ptr Tensor)
_cholesky_helper_cuda_tb _self _upper =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_cholesky_helper_cuda(
    *$(at::Tensor* _self)
  , $(bool _upper)));
  }|]

_cholesky_solve_helper_cuda_ttb
  :: Ptr Tensor
  -> Ptr Tensor
  -> CBool
  -> IO (Ptr Tensor)
_cholesky_solve_helper_cuda_ttb _self _A _upper =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_cholesky_solve_helper_cuda(
    *$(at::Tensor* _self)
  , *$(at::Tensor* _A)
  , $(bool _upper)));
  }|]

_histc_out_cuda_Ttiss
  :: Ptr Tensor
  -> Ptr Tensor
  -> CInt
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
_histc_out_cuda_Ttiss _out _self _bins _min _max =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_histc_out_cuda(
    *$(at::Tensor* _out)
  , *$(at::Tensor* _self)
  , $(int _bins)
  , *$(at::Scalar* _min)
  , *$(at::Scalar* _max)));
  }|]

_histc_cuda_tiss
  :: Ptr Tensor
  -> CInt
  -> Ptr Scalar
  -> Ptr Scalar
  -> IO (Ptr Tensor)
_histc_cuda_tiss _self _bins _min _max =
  [C.block| at::Tensor* { return new at::Tensor(at::native::_histc_cuda(
    *$(at::Tensor* _self)
  , $(int _bins)
  , *$(at::Scalar* _min)
  , *$(at::Scalar* _max)));
  }|]

adaptive_avg_pool2d_out_cuda_Ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
adaptive_avg_pool2d_out_cuda_Ttl _output _self _output_size =
  [C.block| at::Tensor* { return new at::Tensor(at::native::adaptive_avg_pool2d_out_cuda(
    *$(at::Tensor* _output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _output_size)));
  }|]

adaptive_avg_pool2d_cuda_tl
  :: Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
adaptive_avg_pool2d_cuda_tl _self _output_size =
  [C.block| at::Tensor* { return new at::Tensor(at::native::adaptive_avg_pool2d_cuda(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _output_size)));
  }|]

adaptive_avg_pool2d_backward_cuda_tt
  :: Ptr Tensor
  -> Ptr Tensor
  -> IO (Ptr Tensor)
adaptive_avg_pool2d_backward_cuda_tt _grad_output _self =
  [C.block| at::Tensor* { return new at::Tensor(at::native::adaptive_avg_pool2d_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)));
  }|]

fractional_max_pool2d_out_cuda_TTtllt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr Tensor
  -> IO (Ptr (Tensor,Tensor))
fractional_max_pool2d_out_cuda_TTtllt _output _indices _self _kernel_size _output_size _random_samples =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::fractional_max_pool2d_out_cuda(
    *$(at::Tensor* _output)
  , *$(at::Tensor* _indices)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _kernel_size)
  , *$(at::IntArrayRef* _output_size)
  , *$(at::Tensor* _random_samples)));
  }|]

fractional_max_pool2d_cuda_tllt
  :: Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr Tensor
  -> IO (Ptr (Tensor,Tensor))
fractional_max_pool2d_cuda_tllt _self _kernel_size _output_size _random_samples =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::fractional_max_pool2d_cuda(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _kernel_size)
  , *$(at::IntArrayRef* _output_size)
  , *$(at::Tensor* _random_samples)));
  }|]

fractional_max_pool2d_backward_out_cuda_Tttllt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr Tensor
  -> IO (Ptr Tensor)
fractional_max_pool2d_backward_out_cuda_Tttllt _grad_input _grad_output _self _kernel_size _output_size _indices =
  [C.block| at::Tensor* { return new at::Tensor(at::native::fractional_max_pool2d_backward_out_cuda(
    *$(at::Tensor* _grad_input)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _kernel_size)
  , *$(at::IntArrayRef* _output_size)
  , *$(at::Tensor* _indices)));
  }|]

fractional_max_pool2d_backward_cuda_ttllt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr Tensor
  -> IO (Ptr Tensor)
fractional_max_pool2d_backward_cuda_ttllt _grad_output _self _kernel_size _output_size _indices =
  [C.block| at::Tensor* { return new at::Tensor(at::native::fractional_max_pool2d_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _kernel_size)
  , *$(at::IntArrayRef* _output_size)
  , *$(at::Tensor* _indices)));
  }|]

fractional_max_pool3d_out_cuda_TTtllt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr Tensor
  -> IO (Ptr (Tensor,Tensor))
fractional_max_pool3d_out_cuda_TTtllt _output _indices _self _kernel_size _output_size _random_samples =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::fractional_max_pool3d_out_cuda(
    *$(at::Tensor* _output)
  , *$(at::Tensor* _indices)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _kernel_size)
  , *$(at::IntArrayRef* _output_size)
  , *$(at::Tensor* _random_samples)));
  }|]

fractional_max_pool3d_cuda_tllt
  :: Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr Tensor
  -> IO (Ptr (Tensor,Tensor))
fractional_max_pool3d_cuda_tllt _self _kernel_size _output_size _random_samples =
  [C.block| std::tuple<at::Tensor,at::Tensor>* { return new std::tuple<at::Tensor,at::Tensor>(at::native::fractional_max_pool3d_cuda(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _kernel_size)
  , *$(at::IntArrayRef* _output_size)
  , *$(at::Tensor* _random_samples)));
  }|]

fractional_max_pool3d_backward_out_cuda_Tttllt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr Tensor
  -> IO (Ptr Tensor)
fractional_max_pool3d_backward_out_cuda_Tttllt _grad_input _grad_output _self _kernel_size _output_size _indices =
  [C.block| at::Tensor* { return new at::Tensor(at::native::fractional_max_pool3d_backward_out_cuda(
    *$(at::Tensor* _grad_input)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _kernel_size)
  , *$(at::IntArrayRef* _output_size)
  , *$(at::Tensor* _indices)));
  }|]

fractional_max_pool3d_backward_cuda_ttllt
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> Ptr IntList
  -> Ptr Tensor
  -> IO (Ptr Tensor)
fractional_max_pool3d_backward_cuda_ttllt _grad_output _self _kernel_size _output_size _indices =
  [C.block| at::Tensor* { return new at::Tensor(at::native::fractional_max_pool3d_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _kernel_size)
  , *$(at::IntArrayRef* _output_size)
  , *$(at::Tensor* _indices)));
  }|]

reflection_pad1d_out_cuda_Ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
reflection_pad1d_out_cuda_Ttl _output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::reflection_pad1d_out_cuda(
    *$(at::Tensor* _output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

reflection_pad1d_cuda_tl
  :: Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
reflection_pad1d_cuda_tl _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::reflection_pad1d_cuda(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

reflection_pad1d_backward_out_cuda_Tttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
reflection_pad1d_backward_out_cuda_Tttl _grad_input _grad_output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::reflection_pad1d_backward_out_cuda(
    *$(at::Tensor* _grad_input)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

reflection_pad1d_backward_cuda_ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
reflection_pad1d_backward_cuda_ttl _grad_output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::reflection_pad1d_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

reflection_pad2d_out_cuda_Ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
reflection_pad2d_out_cuda_Ttl _output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::reflection_pad2d_out_cuda(
    *$(at::Tensor* _output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

reflection_pad2d_cuda_tl
  :: Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
reflection_pad2d_cuda_tl _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::reflection_pad2d_cuda(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

reflection_pad2d_backward_out_cuda_Tttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
reflection_pad2d_backward_out_cuda_Tttl _grad_input _grad_output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::reflection_pad2d_backward_out_cuda(
    *$(at::Tensor* _grad_input)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

reflection_pad2d_backward_cuda_ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
reflection_pad2d_backward_cuda_ttl _grad_output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::reflection_pad2d_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad1d_out_cuda_Ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad1d_out_cuda_Ttl _output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad1d_out_cuda(
    *$(at::Tensor* _output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad1d_cuda_tl
  :: Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad1d_cuda_tl _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad1d_cuda(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad1d_backward_out_cuda_Tttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad1d_backward_out_cuda_Tttl _grad_input _grad_output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad1d_backward_out_cuda(
    *$(at::Tensor* _grad_input)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad1d_backward_cuda_ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad1d_backward_cuda_ttl _grad_output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad1d_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad2d_out_cuda_Ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad2d_out_cuda_Ttl _output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad2d_out_cuda(
    *$(at::Tensor* _output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad2d_cuda_tl
  :: Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad2d_cuda_tl _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad2d_cuda(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad2d_backward_out_cuda_Tttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad2d_backward_out_cuda_Tttl _grad_input _grad_output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad2d_backward_out_cuda(
    *$(at::Tensor* _grad_input)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad2d_backward_cuda_ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad2d_backward_cuda_ttl _grad_output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad2d_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad3d_out_cuda_Ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad3d_out_cuda_Ttl _output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad3d_out_cuda(
    *$(at::Tensor* _output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad3d_cuda_tl
  :: Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad3d_cuda_tl _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad3d_cuda(
    *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad3d_backward_out_cuda_Tttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad3d_backward_out_cuda_Tttl _grad_input _grad_output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad3d_backward_out_cuda(
    *$(at::Tensor* _grad_input)
  , *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

replication_pad3d_backward_cuda_ttl
  :: Ptr Tensor
  -> Ptr Tensor
  -> Ptr IntList
  -> IO (Ptr Tensor)
replication_pad3d_backward_cuda_ttl _grad_output _self _padding =
  [C.block| at::Tensor* { return new at::Tensor(at::native::replication_pad3d_backward_cuda(
    *$(at::Tensor* _grad_output)
  , *$(at::Tensor* _self)
  , *$(at::IntArrayRef* _padding)));
  }|]

